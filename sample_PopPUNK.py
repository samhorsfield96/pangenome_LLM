import argparse
from collections import defaultdict
import random
import os
import math
import pickle

def parse_args():
    """
    Parse command-line arguments.

    This function parses the command-line arguments provided by the user and returns
    a Namespace object containing the parsed arguments.
    """
    parser = argparse.ArgumentParser(description="Sample PopPUNK output into representative datasets of each cluster.")
    parser.add_argument("--prop", type=float, default=0.1, help="Proportion of each cluster to sample to. Default=0.1")
    parser.add_argument("--number", type=float, default=None, help="Instead of sampling to proportion, sample to this number for each cluster.")
    parser.add_argument("--clusters", type=str, required=True, help="Path to clusters file generated by PopPUNK.")
    parser.add_argument("--genomes", type=str, required=True, help="Path to PopPUNK infile to enable generation of paths to sample.")
    parser.add_argument("--outpref", type=str, default="sampled_genomes", help="Output prefix. Default = stratified_genomes")
    parser.add_argument("--seed", type=int, default=42, help="Random seed for reproducibility")

    args = parser.parse_args()

    return args

def main():

    args = parse_args()
    clusters = args.clusters
    genomes = args.genomes
    prop = args.prop
    number = args.number
    outpref = args.outpref
    seed = args.seed

    # set seed
    random.seed(seed)

    # hold set of genomes being analysed
    genome_dict = {}
    with open(genomes, "r") as f:
            while True:
                line = f.readline()
                if not line:
                    break
                
                split_line = line.rstrip().split("\t")
                genome_dict[split_line[0]] = split_line[1]

    cluster_dict = defaultdict(list)
    with open(clusters, "r") as f:
        f.readline()
        for line in f:
            split_line = line.strip().split(",")
            
            # add genome to cluster entry if in dataset
            if split_line[0] in genome_dict:
                cluster_dict[split_line[1]].append(split_line[0])

    # for each cluster, shuffle and randomly assign to training, don't keep tally as just all remaining genomes are training
    cluster_len_dict = {}
    final_cluster_dict = {}
    for cluster in cluster_dict.keys():
        genome_list = cluster_dict[cluster]
        
        # keep track of original cluster size 
        cluster_len_dict[cluster] = len(genome_list)

        # calculate number of genomes to move and then shuffle
        if number == None:
            num_to_move = math.ceil(len(genome_list) * prop)
        else:
            num_to_move = number
        
        random.shuffle(genome_list)

        # remove genomes to new list
        final_cluster_dict[cluster] = genome_list[:num_to_move + 1]

    # sample genomes from input file
    with open(outpref + "_genomes.txt", 'w') as o1, open(outpref + "_clusters.csv", 'w') as o2:
        o2.write("Taxon,Cluster\n")
        for cluster_id, genome_list in final_cluster_dict.items():
            for genome_id in genome_list:
                o1.write(genome_dict[genome_id] + "\n")
                o2.write(genome_id + "," + str(cluster_id) + "\n")
                
if __name__ == "__main__":
    main()