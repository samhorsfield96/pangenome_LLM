
import argparse
import umap
import umap.plot
import pandas as pd
from collections import OrderedDict, Counter
from itertools import chain
import numpy as np
from sklearn.datasets import load_digits
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import os

def get_options():
    description = "Merges clusters from batched mmseqs2 runs."
    parser = argparse.ArgumentParser(description=description,
                                        prog='python merge_mmseqs.py')
    IO = parser.add_argument_group('Input/options.out')
    IO.add_argument('--embeddings',
                    required=True,
                    help='Embeddings file generated by compute_sequence_embedding.py')
    IO.add_argument('--labels',
                    default=None,
                    help='PopPUNK csv file describing genome names in first column in same order as in embeddings file. Can have second column with assigned clusters.')
    IO.add_argument('--max-labels',
                    default=None,
                    type=int,
                    help='Maximum number of colours to plot. Will plot largest N labels and set all rest as the same')
    IO.add_argument('--outpref',
                default="output",
                help='Output prefix. Default = "output"')
    return parser.parse_args()

def main():
    options = get_options()
    embeddings = options.embeddings
    labels = options.labels
    outpref = options.outpref
    clusters = options.clusters

    labels_dict = OrderedDict()
    if labels != None:
        print("Reading labels...")
        with open(labels, "r") as i1:
            i1.readline()
            for line in i1:
                split_line = line.rstrip().split(",")
                if len(split_line) >= 2:
                    labels_dict[split_line[0]] = split_line[1]
                else:
                    labels_dict[split_line[0]] = "NA"

    if args.max_labels != None:
        all_labels = chain.from_iterable(labels_dict.values())
        counter = Counter(all_elements)

        # Get the top entries
        top_labels = {item for item, _ in counter.most_common(args.max_labels)}

        filtered_data = {
            key: [val if val in top_labels else "NA" for val in vals]
            for key, vals in labels_dict.items()
        }

        labels_dict = filtered_data
        
    # read embeddings
    print("Reading embeddings...")
    df = pd.read_csv(embeddings, header=None)
    #print(df)

    # parse genome ids and remove file extensions
    genome_IDs = df[0].to_list()
    genome_IDs = [os.path.splitext(os.path.splitext(x)[0])[0] for x in genome_IDs]

    df = df.drop([0], axis=1)
    #print(genome_IDs)
    #df.insert(loc=0, column='Cluster', value=cluster_list)
    #df.insert(loc=0, column='Sample', value=sample_list)
    
    reducer = umap.UMAP(random_state=42)

    print("Generating UMAP...")
    mapper = reducer.fit(df)
    UMAP_embedding = reducer.transform(df)

    # get metadata, ensuring in same order as files passed
    sample_list = [x for x in genome_IDs if x in labels_dict]
    cluster_list = [labels_dict[x] for x in genome_IDs if x in labels_dict]
    #print(cluster_list)
    #print(sample_list)
    #norm_cluster = np.array(cluster_list) / max(cluster_list)

    UMAP_embedding_df = pd.DataFrame(UMAP_embedding)
    UMAP_embedding_df.insert(loc=0, column='Cluster', value=cluster_list)
    UMAP_embedding_df.insert(loc=0, column='Sample', value=sample_list)

    UMAP_embedding_df.columns = ['Sample', 'Cluster', 'UMAP1', 'UMAP2']
    UMAP_embedding_df.to_csv(outpref + '.csv', index=False)

    print("Plotting UMAP...")
    if labels != None and cluster_list[0] != None:
        # unique_strings = list(set(cluster_list))
        # string_to_int = {s: i for i, s in enumerate(unique_strings)}
        # normalized_values = np.array([string_to_int[s] for s in cluster_list]) / (len(unique_strings) - 1)
        # cmap = cm.get_cmap("cubehelix")
        
        p = umap.plot.points(mapper, labels=UMAP_embedding_df['Cluster'], theme='fire')

        # plt.scatter(
        # UMAP_embedding[:, 0],
        # UMAP_embedding[:, 1],
        # c=normalized_values,
        # cmap=cmap)
        # plt.gca().set_aspect('equal', 'datalim')
        
    else:
        # plt.scatter(
        # UMAP_embedding[:, 0],
        # UMAP_embedding[:, 1])
        # plt.gca().set_aspect('equal', 'datalim')

        p = umap.plot.points(mapper)

    print("Saving file...")
    plt.savefig(outpref + ".png", dpi=300, bbox_inches="tight")

if __name__ == "__main__":
    main()