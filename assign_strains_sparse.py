import argparse
import umap
import umap.plot
import pandas as pd
import pickle
import numpy as np
import scipy as sp
import os
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score, balanced_accuracy_score, precision_score, recall_score

def get_options():
    description = "Assigns strains using ppsketchlib distances"
    parser = argparse.ArgumentParser(description=description,
                                        prog='python assign_strains_sparse.py')
    IO = parser.add_argument_group('Input/options.out')
    IO.add_argument('--distances',
                    required=True,
                    help='Distances .npz file generated by ppsketchlib')
    IO.add_argument('--samples',
                    required=True,
                    help='Samples .pkl file generated by ppsketchlib')
    IO.add_argument('--prompt_labels',
                    required=True,
                    help='PopPUNK csv file describing genome names in first column in same order as in embeddings file. Can have second column with assigned clusters.')
    IO.add_argument('--query_labels',
                    required=True,
                    help='PopPUNK csv file describing genome names in first column in same order as in embeddings file. Can have second column with assigned clusters.')
    IO.add_argument("--n_neighbors", default="5", help="Number of neighbors for KNN classification.")
    IO.add_argument('--outpref',
                default="output",
                help='Output prefix. Default = "output"')
    
    return parser.parse_args()

def main():
    options = get_options()
    distances = options.distances
    samples = options.samples
    prompt_labels = options.prompt_labels
    query_labels = options.query_labels
    outpref = options.outpref

    prompt_genome_labels = []
    prompt_cluster_assignments = []
    with open(options.prompt_labels, "r") as i:
        i.readline()
        for line in i:
            split_line = line.rstrip().split(",")
            genome_name = split_line[0]
            prompt_genome_labels.append(genome_name)
            prompt_cluster_assignments.append(split_line[1])
    
    query_genome_labels = []
    query_cluster_assignments = []
    with open(options.query_labels, "r") as i:
        i.readline()
        for line in i:
            split_line = line.rstrip().split(",")
            genome_name = split_line[0]
            query_genome_labels.append(genome_name)
            query_cluster_assignments.append(split_line[1])

        
    # read embeddings
    print("Reading distances...")
    distance_matrix = sp.sparse.load_npz(distances).tocsr()

    # parse genome ids and remove file extensions
    with open(samples, 'rb') as f:
        genome_IDs = pickle.load(f)
    genome_IDs = genome_IDs[0]
    genome_IDs = [os.path.splitext(os.path.splitext(x)[0])[0] for x in genome_IDs]

    # downsample genomes IDs and df
    train_idx = [i for i, x in enumerate(genome_IDs) if x in set(prompt_genome_labels)]
    test_idx = [i for i, x in enumerate(genome_IDs) if x in set(query_genome_labels)]
    
    # Extract submatrices of the distance matrix
    dist_train = distance_matrix[train_idx, :][:, train_idx]
    dist_test  = distance_matrix[test_idx, :][:, train_idx]

    #print(f"dist_train: {dist_train}")
    #print(f"dist_test: {dist_test}")

    y_train = np.array(prompt_cluster_assignments)
    y_test = np.array(query_cluster_assignments)

    #print(f"y_train: {y_train}")
    #print(f"y_test: {y_test}")

    print("Running kNN")
    n_neighbors_list = [int(k) for k in options.n_neighbors.split(",")]
    per_k_accuracy = []
    for n_neighbors in n_neighbors_list:
        try:
            knn = KNeighborsClassifier(n_neighbors=n_neighbors, metric="precomputed")
            knn.fit(dist_train, y_train)

            # predict from classifier
            y_pred = knn.predict(dist_test)

            query_list_df_pred = pd.DataFrame(columns=['Taxon', 'predicted_label'])
            query_list_df_pred['Taxon'] = query_genome_labels
            query_list_df_pred['predicted_label'] = y_pred
            query_list_df_pred.to_csv(options.outpref + f"_k_{n_neighbors}_predictions.tsv", sep='\t', index=False)
           
            unique_labels = np.unique(y_test)
            # Per-class accuracy
            per_label_accuracy = []
            for label in unique_labels:
                # Select only test examples of this class
                idx = y_test == label
                y_test_label_count = np.sum(idx)
                y_train_label_count = np.sum(y_train == label)
                label_acc = accuracy_score(y_test[idx], y_pred[idx])
                label_precision = precision_score(y_test, y_pred, labels=[label], average='macro', zero_division=0)
                label_recall = recall_score(y_test, y_pred, labels=[label], average='macro', zero_division=0)

                per_label_accuracy.append({
                    'K': n_neighbors,
                    'Label': label,
                    'Precision': label_precision,
                    'Recall': label_recall,
                    'Accuracy': label_acc,
                    'Query_count' : y_test_label_count,
                    'Test_count': y_train_label_count
                })
            
            # Overall accuracy
            all_acc = accuracy_score(y_test, y_pred)
            all_acc_balanced = balanced_accuracy_score(y_test, y_pred)
            overall_precision_macro = precision_score(y_test, y_pred, average='macro', zero_division=0)
            overall_recall_macro = recall_score(y_test, y_pred, average='macro', zero_division=0)
            overall_precision_weighted = precision_score(y_test, y_pred, average='weighted', zero_division=0)
            overall_recall_weighted = recall_score(y_test, y_pred, average='weighted', zero_division=0)

            per_label_accuracy.append({
                'K': n_neighbors,
                'Label': "overall",
                'Accuracy': all_acc,
                'Precision': overall_precision_macro,
                'Recall': overall_recall_macro,
                'Query_count' : len(query_cluster_assignments),
                'Test_count': len(prompt_cluster_assignments)
                })
            per_label_accuracy.append({
                'K': n_neighbors,
                'Label': "overall_balanced",
                'Accuracy': all_acc_balanced,
                'Precision': overall_precision_weighted,
                'Recall': overall_recall_weighted,
                'Query_count' : len(query_cluster_assignments),
                'Test_count': len(prompt_cluster_assignments)
                })
            
            # save to overall dataframe:
            per_k_accuracy.append({
                'K': n_neighbors,
                'Label': "overall",
                'Accuracy': all_acc,
                'Precision': overall_precision_macro,
                'Recall': overall_recall_macro,
                'Query_count' : len(query_cluster_assignments),
                'Test_count': len(prompt_cluster_assignments)
            })
            per_k_accuracy.append({
                'K': n_neighbors,
                'Label': "overall_balanced",
                'Accuracy': all_acc_balanced,
                'Precision': overall_precision_weighted,
                'Recall': overall_recall_weighted,
                'Query_count' : len(query_cluster_assignments),
                'Test_count': len(prompt_cluster_assignments)
            })

            # Convert to DataFrame
            per_label_df = pd.DataFrame(per_label_accuracy)

            # Save to TSV
            per_label_df.to_csv(options.outpref + f"_k_{n_neighbors}_per_label_accuracy.tsv", sep='\t', index=False)
        except Exception as error:
            print(f"Failed to train at K={n_neighbors}")
            print("Error here:", error)
            continue
    
    # Convert to DataFrame
    per_k_df = pd.DataFrame(per_k_accuracy)

    # Save to TSV
    per_k_df.to_csv(options.outpref + "_overall_accuracy.tsv", sep='\t', index=False)

if __name__ == "__main__":
    main()