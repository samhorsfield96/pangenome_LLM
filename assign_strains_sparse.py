import argparse
import pandas as pd
import pickle
import numpy as np
import scipy as sp
import os
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score, balanced_accuracy_score, precision_score, recall_score

def long_to_square(dist_vec, n, m):
    """
    Convert flat distance vector into an n√óm NumPy array (row-major).
    """
    if dist_vec.size != n * m:
        raise ValueError(f"dist_vec length {dist_vec.size} != n*m ({n*m})")
    return dist_vec.reshape((n, m), order="C")  # row-major

def read_distances_file(distances, samples, genome_labels):
    # parse genome ids and remove file extensions
    with open(samples, 'rb') as f:
        genome_IDs = pickle.load(f)

    test_genome_IDs = genome_IDs[1]
    train_genome_IDs = genome_IDs[0]
    test_genome_IDs = [os.path.splitext(os.path.splitext(x)[0])[0] for x in test_genome_IDs]
    train_genome_IDs = [os.path.splitext(os.path.splitext(x)[0])[0] for x in train_genome_IDs]

    # read embeddings
    if ".npz" in distances:
        distance_matrix = sp.sparse.load_npz(distances).tocsr()        
    else:
        distance_matrix = np.load(distances)
        # sample just accessory distances
        distance_matrix = long_to_square(distance_matrix[:, [1]], len(test_genome_IDs), len(train_genome_IDs))

    # reorder
    label_to_idx = {label: i for i, label in enumerate(genome_labels)}
    idx = [label_to_idx[x] for x in test_genome_IDs if x in label_to_idx]
    dist = distance_matrix[idx, :]

    # convert to identities
    dist[dist.nonzero()] = 1.0 - dist[dist.nonzero()]

    return dist, test_genome_IDs

def get_options():
    description = "Assigns strains using ppsketchlib distances"
    parser = argparse.ArgumentParser(description=description,
                                        prog='python assign_strains_sparse.py')
    IO = parser.add_argument_group('Input/options.out')
    IO.add_argument('--train_distances',
                    required=True,
                    help='Distances .npz/.npy file generated by ppsketchlib for kNN training')
    IO.add_argument('--train_samples',
                    required=True,
                    help='Samples .pkl file generated by ppsketchlib for kNN training')
    IO.add_argument('--query_distances',
                    required=True,
                    help='Distances .npz/.npy file generated by ppsketchlib for kNN querying')
    IO.add_argument('--query_samples',
                    required=True,
                    help='Samples .pkl file generated by ppsketchlib for kNN querying')
    IO.add_argument('--train_labels',
                    required=True,
                    help='PopPUNK csv file describing genome names in first column in same order as in embeddings file for kNN training.')
    IO.add_argument('--query_labels',
                    required=True,
                    help='PopPUNK csv file describing genome names in first column in same order as in embeddings file for kNN querying.')
    IO.add_argument("--n_neighbors", default="5", help="Number of neighbors for KNN classification.")
    IO.add_argument('--outpref',
                default="output",
                help='Output prefix. Default = "output"')
    
    return parser.parse_args()

def main():
    options = get_options()
    train_distances = options.train_distances
    train_samples = options.train_samples
    query_distances = options.query_distances
    query_samples = options.query_samples
    train_labels = options.train_labels
    query_labels = options.query_labels
    outpref = options.outpref

    train_genome_labels = []
    train_cluster_assignments = []
    with open(options.train_labels, "r") as i:
        i.readline()
        for line in i:
            split_line = line.rstrip().split(",")
            genome_name = split_line[0]
            train_genome_labels.append(genome_name)
            train_cluster_assignments.append(split_line[1])
    
    query_genome_labels = []
    query_cluster_assignments = []
    with open(options.query_labels, "r") as i:
        i.readline()
        for line in i:
            split_line = line.rstrip().split(",")
            genome_name = split_line[0]
            query_genome_labels.append(genome_name)
            query_cluster_assignments.append(split_line[1])


    print("Reading distances")
    dist_train, train_genome_IDs = read_distances_file(train_distances, train_samples, train_genome_labels)
    dist_test, test_genome_IDs = read_distances_file(query_distances, query_samples, query_genome_labels)
    
    #print(f"dist_train: {dist_train.shape}")
    #print(f"dist_test: {dist_test.shape}")

    #test_diff = set(query_cluster_assignments).difference(set(train_cluster_assignments))
    #train_diff = set(train_cluster_assignments).difference(set(query_cluster_assignments))
    #print(test_diff)
    #print(train_diff)

    y_train = np.array(train_cluster_assignments)
    y_test = np.array(query_cluster_assignments)

    #print(f"y_train: {y_train.shape}")
    #print(f"y_test: {y_test.shape}")

    print("Running kNN")
    n_neighbors_list = [int(k) for k in options.n_neighbors.split(",")]
    per_k_accuracy = []
    for n_neighbors in n_neighbors_list:
        try:
            knn = KNeighborsClassifier(n_neighbors=n_neighbors, metric="precomputed")
            knn.fit(dist_train, y_train)

            # predict from classifier
            y_pred = knn.predict(dist_test)

            query_list_df_pred = pd.DataFrame(columns=['Taxon', 'predicted_label'])
            query_list_df_pred['Taxon'] = query_genome_labels
            query_list_df_pred['predicted_label'] = y_pred
            query_list_df_pred.to_csv(options.outpref + f"_k_{n_neighbors}_predictions.tsv", sep='\t', index=False)
           
            unique_labels = np.unique(y_test)
            # Per-class accuracy
            per_label_accuracy = []
            for label in unique_labels:
                # Select only test examples of this class
                idx = y_test == label
                y_test_label_count = np.sum(idx)
                y_train_label_count = np.sum(y_train == label)
                label_acc = accuracy_score(y_test[idx], y_pred[idx])
                label_precision = precision_score(y_test, y_pred, labels=[label], average='macro', zero_division=0)
                label_recall = recall_score(y_test, y_pred, labels=[label], average='macro', zero_division=0)

                per_label_accuracy.append({
                    'K': n_neighbors,
                    'Label': label,
                    'Precision': label_precision,
                    'Recall': label_recall,
                    'Accuracy': label_acc,
                    'Query_count' : y_test_label_count,
                    'Test_count': y_train_label_count
                })
            
            # Overall accuracy
            all_acc = accuracy_score(y_test, y_pred)
            all_acc_balanced = balanced_accuracy_score(y_test, y_pred)
            overall_precision_macro = precision_score(y_test, y_pred, average='macro', zero_division=0)
            overall_recall_macro = recall_score(y_test, y_pred, average='macro', zero_division=0)
            overall_precision_weighted = precision_score(y_test, y_pred, average='weighted', zero_division=0)
            overall_recall_weighted = recall_score(y_test, y_pred, average='weighted', zero_division=0)

            per_label_accuracy.append({
                'K': n_neighbors,
                'Label': "overall",
                'Accuracy': all_acc,
                'Precision': overall_precision_macro,
                'Recall': overall_recall_macro,
                'Query_count' : len(query_cluster_assignments),
                'Test_count': len(train_cluster_assignments)
                })
            per_label_accuracy.append({
                'K': n_neighbors,
                'Label': "overall_balanced",
                'Accuracy': all_acc_balanced,
                'Precision': overall_precision_weighted,
                'Recall': overall_recall_weighted,
                'Query_count' : len(query_cluster_assignments),
                'Test_count': len(train_cluster_assignments)
                })
            
            # save to overall dataframe:
            per_k_accuracy.append({
                'K': n_neighbors,
                'Label': "overall",
                'Accuracy': all_acc,
                'Precision': overall_precision_macro,
                'Recall': overall_recall_macro,
                'Query_count' : len(query_cluster_assignments),
                'Test_count': len(train_cluster_assignments)
            })
            per_k_accuracy.append({
                'K': n_neighbors,
                'Label': "overall_balanced",
                'Accuracy': all_acc_balanced,
                'Precision': overall_precision_weighted,
                'Recall': overall_recall_weighted,
                'Query_count' : len(query_cluster_assignments),
                'Test_count': len(train_cluster_assignments)
            })

            # Convert to DataFrame
            per_label_df = pd.DataFrame(per_label_accuracy)

            # Save to TSV
            per_label_df.to_csv(options.outpref + f"_k_{n_neighbors}_per_label_accuracy.tsv", sep='\t', index=False)
        except Exception as error:
            print(f"Failed to train at K={n_neighbors}")
            print("Error here:", error)
            continue
    
    # Convert to DataFrame
    per_k_df = pd.DataFrame(per_k_accuracy)

    # Save to TSV
    per_k_df.to_csv(options.outpref + "_overall_accuracy.tsv", sep='\t', index=False)

if __name__ == "__main__":
    main()