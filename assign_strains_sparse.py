import argparse
import pandas as pd
import pickle
import numpy as np
import scipy as sp
import os
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score, balanced_accuracy_score, precision_score, recall_score
from collections import Counter

def knn_predict(dist_test: pd.DataFrame, y_train: dict, k: int = 3) -> pd.Series:
    """
    k-NN prediction using a distance DataFrame and dict of labels.

    Parameters
    ----------
    dist_test : pd.DataFrame
        Rows = query samples, Columns = training samples, Values = distances.
    y_train : dict
        Mapping {training_name: label}.
    k : int
        Number of nearest neighbors to consider.

    Returns
    -------
    pd.Series
        Predicted labels, index aligned with dist_test rows.
    """
    preds = {}

    for query, row in dist_test.iterrows():
        # k nearest training samples
        nearest_idx = row.nsmallest(k).index

        # map to labels
        nearest_labels = [y_train[name] for name in nearest_idx]

        # majority vote
        counts = Counter(nearest_labels)
        preds[query] = counts.most_common(1)[0][0]

    return preds

# based on https://github.com/bacpop/PopPUNK/blob/4097473da3660a29dbb6efccc4dbaa6d1cfc8ed6/scripts/poppunk_extract_distances.py#L1
def isolateNameToLabel(names):
    # useful to have as a function in case we
    # want to remove certain characters
    labels = [os.path.splitext(os.path.basename(name))[0] for name in names]

    return labels

def listDistInts(refSeqs, querySeqs, self=True):
    """Gets the ref and query ID for each row of the distance matrix

    Returns an iterable with ref and query ID pairs by row.

    Args:
        refSeqs (list)
            List of reference sequence names.
        querySeqs (list)
            List of query sequence names.
        self (bool)
            Whether a self-comparison, used when constructing a database.
            Requires refSeqs == querySeqs
            Default is True
    Returns:
        ref, query (str, str)
            Iterable of tuples with ref and query names for each distMat row.
    """
    num_ref = len(refSeqs)
    num_query = len(querySeqs)
    if self:
        if refSeqs != querySeqs:
            raise RuntimeError('refSeqs must equal querySeqs for db building (self = true)')
        for i in range(num_ref):
            for j in range(i + 1, num_ref):
                yield(j, i)
    else:
        comparisons = [(0,0)] * (len(refSeqs) * len(querySeqs))
        for i in range(num_query):
            for j in range(num_ref):
                yield(j, i)

def read_distances_file(distances, samples, query_genome_labels, train_genome_labels):
    # parse genome ids and remove file extensions
    with open(samples, 'rb') as pickle_file:
        rlist, qlist, self = pickle.load(pickle_file)

    # get names order
    r_names = isolateNameToLabel(rlist)
    q_names = isolateNameToLabel(qlist)

    # Load sparse matrix
    sparse = False
    if ".npz" in distances:
        sparse_mat = sparse.load_npz(distances)
        sparse = True
    else:
        X = np.load(distances)

    # create large dataframe, row = query, column = ref
    # Create an n x m DataFrame of zeros
    df = pd.DataFrame(np.zeros((len(q_names), len(r_names))))

    # Assign row names (index)
    df.index = q_names

    # Assign column names
    df.columns = r_names

    # Write distances
    if sparse:
        for (r_index, q_index, dist) in zip(sparse_mat.col, sparse_mat.row, sparse_mat.data):
            df.iat[q_index, r_index] = dist
    else:
        for i, (r_index, q_index) in enumerate(listDistInts(r_names, q_names, r_names == q_names)):
            df.iat[q_index, r_index] = X[i,1]

    return df, q_names

def get_options():
    description = "Assigns strains using ppsketchlib distances"
    parser = argparse.ArgumentParser(description=description,
                                        prog='python assign_strains_sparse.py')
    IO = parser.add_argument_group('Input/options.out')
    IO.add_argument('--query_distances',
                    required=True,
                    help='Distances .npz/.npy file generated by ppsketchlib for kNN querying')
    IO.add_argument('--query_samples',
                    required=True,
                    help='Samples .pkl file generated by ppsketchlib for kNN querying')
    IO.add_argument('--train_labels',
                    required=True,
                    help='PopPUNK csv file describing genome names in first column in same order as in embeddings file for kNN training.')
    IO.add_argument('--query_labels',
                    required=True,
                    help='PopPUNK csv file describing genome names in first column in same order as in embeddings file for kNN querying.')
    IO.add_argument("--n_neighbors", default="5", help="Number of neighbors for KNN classification.")
    IO.add_argument('--outpref',
                default="output",
                help='Output prefix. Default = "output"')
    
    return parser.parse_args()

def main():
    options = get_options()
    query_distances = options.query_distances
    query_samples = options.query_samples
    train_labels = options.train_labels
    query_labels = options.query_labels
    outpref = options.outpref

    train_genome_labels = []
    train_cluster_assignments = {}
    with open(options.train_labels, "r") as i:
        i.readline()
        for line in i:
            split_line = line.rstrip().split(",")
            genome_name = split_line[0]
            train_genome_labels.append(genome_name)
            train_cluster_assignments[genome_name] = split_line[1]
    
    query_genome_labels = []
    query_cluster_assignments = {}
    with open(options.query_labels, "r") as i:
        i.readline()
        for line in i:
            split_line = line.rstrip().split(",")
            genome_name = split_line[0]
            query_genome_labels.append(genome_name)
            query_cluster_assignments[genome_name] = split_line[1]

    print("Reading distances")
    dist_test, test_genome_IDs = read_distances_file(query_distances, query_samples, query_genome_labels, train_genome_labels)

    #print(f"dist_test: {dist_test.shape}")

    y_train = np.array([train_cluster_assignments[col_name] for col_name in dist_test.columns])
    y_test = np.array([query_cluster_assignments[row_name] for row_name in dist_test.index])
    #print(f"y_test: {y_test.shape}")

    print("Running kNN")
    n_neighbors_list = [int(k) for k in options.n_neighbors.split(",")]
    per_k_accuracy = []
    for n_neighbors in n_neighbors_list:
        try:
            # predict from classifier
            query_cluster_predictions = knn_predict(dist_test, train_cluster_assignments, k=n_neighbors)
            y_pred = np.array([query_cluster_predictions[row_name] for row_name in dist_test.index])

            query_list_df_pred = pd.DataFrame(columns=['Taxon', 'predicted_label'])
            query_list_df_pred['Taxon'] = query_genome_labels
            query_list_df_pred['predicted_label'] = y_pred
            query_list_df_pred.to_csv(options.outpref + f"_k_{n_neighbors}_predictions.tsv", sep='\t', index=False)
           
            unique_labels = np.unique(y_test)
            # Per-class accuracy
            per_label_accuracy = []
            for label in unique_labels:
                # Select only test examples of this class
                idx = y_test == label
                y_test_label_count = np.sum(idx)
                y_train_label_count = np.sum(y_train == label)
                label_acc = accuracy_score(y_test[idx], y_pred[idx])
                label_precision = precision_score(y_test, y_pred, labels=[label], average='macro', zero_division=0)
                label_recall = recall_score(y_test, y_pred, labels=[label], average='macro', zero_division=0)

                per_label_accuracy.append({
                    'K': n_neighbors,
                    'Label': label,
                    'Precision': label_precision,
                    'Recall': label_recall,
                    'Accuracy': label_acc,
                    'Query_count' : y_test_label_count,
                    'Test_count': y_train_label_count
                })
            
            # Overall accuracy
            all_acc = accuracy_score(y_test, y_pred)
            all_acc_balanced = balanced_accuracy_score(y_test, y_pred)
            overall_precision_macro = precision_score(y_test, y_pred, average='macro', zero_division=0)
            overall_recall_macro = recall_score(y_test, y_pred, average='macro', zero_division=0)
            overall_precision_weighted = precision_score(y_test, y_pred, average='weighted', zero_division=0)
            overall_recall_weighted = recall_score(y_test, y_pred, average='weighted', zero_division=0)

            per_label_accuracy.append({
                'K': n_neighbors,
                'Label': "overall",
                'Accuracy': all_acc,
                'Precision': overall_precision_macro,
                'Recall': overall_recall_macro,
                'Query_count' : len(query_cluster_assignments),
                'Test_count': len(train_cluster_assignments)
                })
            per_label_accuracy.append({
                'K': n_neighbors,
                'Label': "overall_balanced",
                'Accuracy': all_acc_balanced,
                'Precision': overall_precision_weighted,
                'Recall': overall_recall_weighted,
                'Query_count' : len(query_cluster_assignments),
                'Test_count': len(train_cluster_assignments)
                })
            
            # save to overall dataframe:
            per_k_accuracy.append({
                'K': n_neighbors,
                'Label': "overall",
                'Accuracy': all_acc,
                'Precision': overall_precision_macro,
                'Recall': overall_recall_macro,
                'Query_count' : len(query_cluster_assignments),
                'Test_count': len(train_cluster_assignments)
            })
            per_k_accuracy.append({
                'K': n_neighbors,
                'Label': "overall_balanced",
                'Accuracy': all_acc_balanced,
                'Precision': overall_precision_weighted,
                'Recall': overall_recall_weighted,
                'Query_count' : len(query_cluster_assignments),
                'Test_count': len(train_cluster_assignments)
            })

            # Convert to DataFrame
            per_label_df = pd.DataFrame(per_label_accuracy)

            # Save to TSV
            per_label_df.to_csv(options.outpref + f"_k_{n_neighbors}_per_label_accuracy.tsv", sep='\t', index=False)
        except Exception as error:
            print(f"Failed to train at K={n_neighbors}")
            print("Error here:", error)
            continue
    
    # Convert to DataFrame
    per_k_df = pd.DataFrame(per_k_accuracy)

    # Save to TSV
    per_k_df.to_csv(options.outpref + "_overall_accuracy.tsv", sep='\t', index=False)

if __name__ == "__main__":
    main()